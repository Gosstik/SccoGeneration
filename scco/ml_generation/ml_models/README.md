## Файлы с секретами
1) Файл `api_token.secret.env` по пути `scco/ml_generation/ml_models/src/ml_models/gigachat_api_gate/api_token.secret.env`
   Содержимое файла:
   ```bash
   GIGACHAT_API_SCOPE="GIGACHAT_API_PERS"
   GIGACHAT_API_CLIENT_ID=<see_below>
   GIGACHAT_API_CLIENT_SECRET=<see_below>
   ```
   Для получения значений `GIGACHAT_API_CLIENT_ID` и `GIGACHAT_API_CLIENT_SECRET` нужно:
   1) Перейти на сайт [developers.sber.ru](https://developers.sber.ru/docs/ru/gigachat/individuals-quickstart)
   2) В правой части экрана нажать `подключить сервис` -> `начать пользоваться как физлицо`
   3) Зайти в аккаунт (например, по номеру телефона)
   4) В правой части экрана скопировать `Client ID` и вставить в переменную `GIGACHAT_API_CLIENT_ID`
   5) Нажать `Generate new` -> `Generate new one anyway`.
   6) Скопировать значение `Client Secret` в переменную `GIGACHAT_API_CLIENT_SECRET`
   **Note** Для юридических лиц инструкция немного другая, подробнее узнавайте на сайте.

<!-------------------------------------------------------------------->

### Использование
* Все модели располагаются в пакете `ml_models`.  
 Внутри в дирректориях co_gen, white_list_generation находятся готовые модели.  
 Для примера рассмотрим более сложную: co_gen
 В ml_models/gigachat_api_gate/api.py можно найти базовый класс всех моделей-оберток GigaChat'а  
 Чтобы создать свою модель надо:  
   1) Унаследовать свою модель от GenerateGateWrapper
   2) Переопределить generate - из request'а получает нужный ответ, в ней нужно:
      - вызвать ```self._set_system_params(request, make_system_prompt)```, где ```make_system_prompt``` берет pсистемный промпт (строку с описанием предназначения модели)
      - создать промпт, используя: ```self.system_prompt + ... ```  
         ```self.system_prompt``` создается сам, вам нужно добавить user-промпт, т.е. сообщение обрабатываемое. Рекомендуется просто передать необходимю строку в utils.UserMessageHandler как делается в co_gen.api
   3) Вызвать ```self.gate.generate_request(...)``` - от созданного выше промпта
   4) Результат можно обработать как делается в co_gen/api.py или так и оставить - там много ненужной информации, приходящей в запросе
   5) Также рекомендуется переопределить конструктор вашей обертки, где нужно прокринуть в родителя конкретный конфиг с параметрами

   Теперь нужно просто создать экземпляр обертки и вызвать метод generate(request), где в request обязательно должны быть поля, которые вы используете при создании системного промпта (в функции, которую передаете в self._set_system_params(request, ...))

- Общие рекомендации:  
   - Придерживаться неймингов авторов и все обертки оставлять в api.py
   - Конфиги все хранить в дирректориях с данными обертками и перегружать конструктор передавая конфиг в родителя
   - Если в конфиг должна попасть информация из request просто в промпте из конфига помечать мето и уже в функции ```make_system_prompt``` - которую передаете в ```self._set_system_params``` заменять все на нужные вам параметры

* Настройка конфигов: 
   - Единственный обязательный конфиг в вашей модели: configs/params.ini  
    тут по аналлогии с ml_models/co_gen/configs/params.ini нужно передать все те же параметры, но сменить параметры на нужные вам для данной модели
   - остальный конфиги, названия и параметры не столь принципиальны и использование оставляется на пользователя, рекомендуется придерживаться одного нейминга для базового промпта, пример см в ml_models/co_gen/configs/prompts.ini или в ml_models/white_list_generation/configs/prompts.ini и всю нужную для промптов общую информацию такж указывать в prompts.ini
